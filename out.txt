Running Verilog ITI with parameters:
  Alpha: 0.1
  K (top heads): 5
  Number of problems: 3
Loading Qwen/Qwen2.5-Coder-7B-Instruct...
Model loaded: 28 layers, 28 heads per layer
============================================================
VERILOG ITI EVALUATION
============================================================
Loading dataset...
Preparing training data...
Training probes and computing truthful directions...
Extracting attention head activations...
Selected top 5 heads for intervention
Accuracy range: 1.000 - 1.000

Generating code with and without ITI...
Applying ITI with alpha=0.1 on 5 heads

DEBUG: Intervening on layer 0
  Heads: [1, 5, 7, 16]
  Number of directions: 4
  Alpha: 0.1
  First direction norm: 0.3955
  First std: 0.2070
  Intervention magnitude: 0.0082
  Original activation magnitude: 0.9189
Completed 1/3: zero
Applying ITI with alpha=0.1 on 5 heads

DEBUG: Intervening on layer 0
  Heads: [1, 5, 7, 16]
  Number of directions: 4
  Alpha: 0.1
  First direction norm: 0.3955
  First std: 0.2070
  Intervention magnitude: 0.0082
  Original activation magnitude: 0.9424
Completed 2/3: m2014_q4i
Applying ITI with alpha=0.1 on 5 heads

DEBUG: Intervening on layer 0
  Heads: [1, 5, 7, 16]
  Number of directions: 4
  Alpha: 0.1
  First direction norm: 0.3955
  First std: 0.2070
  Intervention magnitude: 0.0082
  Original activation magnitude: 0.9409
Completed 3/3: step_one

============================================================
EVALUATION COMPLETED
============================================================
Problems evaluated: 3
Top K heads: 5
Alpha (intervention strength): 0.1
Results saved to: verilog_iti_results_K5_alpha0.1.json

Top 10 attention heads by probe accuracy:
  1. Layer 0, Head 1: 1.000
  2. Layer 0, Head 5: 1.000
  3. Layer 0, Head 7: 1.000
  4. Layer 0, Head 16: 1.000
  5. Layer 1, Head 3: 1.000
  6. Layer 1, Head 12: 1.000
  7. Layer 1, Head 15: 1.000
  8. Layer 1, Head 17: 1.000
  9. Layer 1, Head 18: 1.000
  10. Layer 1, Head 23: 1.000

Evaluation completed successfully!
